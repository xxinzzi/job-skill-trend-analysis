# ğŸ” GPT-4o Vision ê¸°ë°˜ ì´ë¯¸ì§€ OCR ëª¨ë“ˆ
# utils/image_ocr.py ë¡œ ì €ì¥ ì¶”ì²œ

import openai
import os
from dotenv import load_dotenv

# Load .env íŒŒì¼ì— ì €ì¥ëœ OPENAI_API_KEY
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")


def extract_job_text_from_image(image_url: str) -> str:
    """
    GPT-4o Vision APIë¥¼ ì‚¬ìš©í•´ ì±„ìš© ê³µê³  ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    :param image_url: ì´ë¯¸ì§€ URL (ì›ë³¸ ë˜ëŠ” Firebase URL ë“±)
    :return: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ (ì‹¤íŒ¨ ì‹œ None)
    """
    try:
        print(f"ğŸ“· GPT-4oë¡œ ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„ ì¤‘...\nURL: {image_url}")

        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "You are a helpful assistant who extracts all visible Korean text from images "
                        "such as job postings, and returns the full content in plain text."
                    )
                },
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "ì±„ìš© ê³µê³  ì´ë¯¸ì§€ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•´ ì¤˜."},
                        {"type": "image_url", "image_url": {"url": image_url}}
                    ]
                }
            ],
            max_tokens=1500
        )

        extracted = response.choices[0].message.content.strip()
        return extracted if extracted else None

    except Exception as e:
        print(f"âŒ GPT-4o Vision OCR ì‹¤íŒ¨: {e}")
        return None
